
@article{mnih_asynchronous_2016,
	title = {Asynchronous {Methods} for {Deep} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1602.01783},
	abstract = {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.},
	urldate = {2020-01-16},
	journal = {arXiv:1602.01783 [cs]},
	author = {Mnih, Volodymyr and Badia, Adrià Puigdomènech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P. and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
	month = jun,
	year = {2016},
	note = {arXiv: 1602.01783},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/ZYPU4IR5/Mnih et al. - 2016 - Asynchronous Methods for Deep Reinforcement Learni.pdf:application/pdf;arXiv.org Snapshot:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/27VWHXNW/1602.html:text/html}
}

@article{campos_skip_2018,
	title = {Skip {RNN}: {Learning} to {Skip} {State} {Updates} in {Recurrent} {Neural} {Networks}},
	shorttitle = {Skip {RNN}},
	url = {http://arxiv.org/abs/1708.06834},
	abstract = {Recurrent Neural Networks (RNNs) continue to show outstanding performance in sequence modeling tasks. However, training RNNs on long sequences often face challenges like slow inference, vanishing gradients and difficulty in capturing long term dependencies. In backpropagation through time settings, these issues are tightly coupled with the large, sequential computational graph resulting from unfolding the RNN in time. We introduce the Skip RNN model which extends existing RNN models by learning to skip state updates and shortens the effective size of the computational graph. This model can also be encouraged to perform fewer state updates through a budget constraint. We evaluate the proposed model on various tasks and show how it can reduce the number of required RNN updates while preserving, and sometimes even improving, the performance of the baseline RNN models. Source code is publicly available at https://imatge-upc.github.io/skiprnn-2017-telecombcn/ .},
	urldate = {2020-01-21},
	journal = {arXiv:1708.06834 [cs]},
	author = {Campos, Victor and Jou, Brendan and Giro-i-Nieto, Xavier and Torres, Jordi and Chang, Shih-Fu},
	month = feb,
	year = {2018},
	note = {arXiv: 1708.06834},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Accepted as conference paper at ICLR 2018},
	file = {arXiv Fulltext PDF:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/NDQDYF8X/Campos et al. - 2018 - Skip RNN Learning to Skip State Updates in Recurr.pdf:application/pdf;arXiv.org Snapshot:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/TXSEWRMW/1708.html:text/html}
}

@article{seo_neural_2018,
	title = {Neural {Speed} {Reading} via {Skim}-{RNN}},
	url = {http://arxiv.org/abs/1711.02085},
	abstract = {Inspired by the principles of speed reading, we introduce Skim-RNN, a recurrent neural network (RNN) that dynamically decides to update only a small fraction of the hidden state for relatively unimportant input tokens. Skim-RNN gives computational advantage over an RNN that always updates the entire hidden state. Skim-RNN uses the same input and output interfaces as a standard RNN and can be easily used instead of RNNs in existing models. In our experiments, we show that Skim-RNN can achieve significantly reduced computational cost without losing accuracy compared to standard RNNs across five different natural language tasks. In addition, we demonstrate that the trade-off between accuracy and speed of Skim-RNN can be dynamically controlled during inference time in a stable manner. Our analysis also shows that Skim-RNN running on a single CPU offers lower latency compared to standard RNNs on GPUs.},
	urldate = {2020-01-21},
	journal = {arXiv:1711.02085 [cs]},
	author = {Seo, Minjoon and Min, Sewon and Farhadi, Ali and Hajishirzi, Hannaneh},
	month = mar,
	year = {2018},
	note = {arXiv: 1711.02085},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: ICLR 2018},
	file = {arXiv Fulltext PDF:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/BK7T9QEG/Seo et al. - 2018 - Neural Speed Reading via Skim-RNN.pdf:application/pdf;arXiv.org Snapshot:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/TTMEA56F/1711.html:text/html}
}

@article{yu_learning_2017,
	title = {Learning to {Skim} {Text}},
	url = {http://arxiv.org/abs/1704.06877},
	abstract = {Recurrent Neural Networks are showing much promise in many sub-areas of natural language processing, ranging from document classification to machine translation to automatic question answering. Despite their promise, many recurrent models have to read the whole text word by word, making it slow to handle long documents. For example, it is difficult to use a recurrent network to read a book and answer questions about it. In this paper, we present an approach of reading text while skipping irrelevant information if needed. The underlying model is a recurrent network that learns how far to jump after reading a few words of the input text. We employ a standard policy gradient method to train the model to make discrete jumping decisions. In our benchmarks on four different tasks, including number prediction, sentiment analysis, news article classification and automatic Q{\textbackslash}\&A, our proposed model, a modified LSTM with jumping, is up to 6 times faster than the standard sequential LSTM, while maintaining the same or even better accuracy.},
	urldate = {2020-01-21},
	journal = {arXiv:1704.06877 [cs]},
	author = {Yu, Adams Wei and Lee, Hongrae and Le, Quoc V.},
	month = apr,
	year = {2017},
	note = {arXiv: 1704.06877},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/3WSXFEAQ/Yu et al. - 2017 - Learning to Skim Text.pdf:application/pdf;arXiv.org Snapshot:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/6PWJB5ZU/1704.html:text/html}
}

@article{gui_long_2018,
	title = {Long {Short}-{Term} {Memory} with {Dynamic} {Skip} {Connections}},
	url = {http://arxiv.org/abs/1811.03873},
	abstract = {In recent years, long short-term memory (LSTM) has been successfully used to model sequential data of variable length. However, LSTM can still experience difficulty in capturing long-term dependencies. In this work, we tried to alleviate this problem by introducing a dynamic skip connection, which can learn to directly connect two dependent words. Since there is no dependency information in the training data, we propose a novel reinforcement learning-based method to model the dependency relationship and connect dependent words. The proposed model computes the recurrent transition functions based on the skip connections, which provides a dynamic skipping advantage over RNNs that always tackle entire sentences sequentially. Our experimental results on three natural language processing tasks demonstrate that the proposed method can achieve better performance than existing methods. In the number prediction experiment, the proposed model outperformed LSTM with respect to accuracy by nearly 20\%.},
	urldate = {2020-01-21},
	journal = {arXiv:1811.03873 [cs]},
	author = {Gui, Tao and Zhang, Qi and Zhao, Lujun and Lin, Yaosong and Peng, Minlong and Gong, Jingjing and Huang, Xuanjing},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.03873},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/BQAEUSNQ/Gui et al. - 2018 - Long Short-Term Memory with Dynamic Skip Connectio.pdf:application/pdf;arXiv.org Snapshot:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/CRG3WLSL/1811.html:text/html}
}

@article{hartl_explainability_2019,
	title = {Explainability and {Adversarial} {Robustness} for {RNNs}},
	url = {http://arxiv.org/abs/1912.09855},
	abstract = {Recurrent Neural Networks (RNNs) yield attractive properties for constructing Intrusion Detection Systems (IDSs) for network data. With the rise of ubiquitous Machine Learning (ML) systems, malicious actors have been catching up quickly to find new ways to exploit ML vulnerabilities for profit. Recently developed adversarial ML techniques focus on computer vision and their applicability to network traffic is not straightforward: Network packets expose fewer features than an image, are sequential and impose several constraints on their features. We show that despite these completely different characteristics, adversarial samples can be generated reliably for RNNs. To understand a classifier's potential for misclassification, we extend existing explainability techniques and propose new ones, suitable particularly for sequential data. Applying them shows that already the first packets of a communication flow are of crucial importance and are likely to be targeted by attackers. Feature importance methods show that even relatively unimportant features can be effectively abused to generate adversarial samples. Since traditional evaluation metrics such as accuracy are not sufficient for quantifying the adversarial threat, we propose the Adversarial Robustness Score (ARS) for comparing IDSs, capturing a common notion of adversarial robustness, and show that an adversarial training procedure can significantly and successfully reduce the attack surface.},
	urldate = {2020-01-21},
	journal = {arXiv:1912.09855 [cs, stat]},
	author = {Hartl, Alexander and Bachl, Maximilian and Fabini, Joachim and Zseby, Tanja},
	month = dec,
	year = {2019},
	note = {arXiv: 1912.09855},
	keywords = {Computer Science - Networking and Internet Architecture, Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Cryptography and Security},
	file = {arXiv Fulltext PDF:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/Q96GWYPR/Hartl et al. - 2019 - Explainability and Adversarial Robustness for RNNs.pdf:application/pdf;arXiv.org Snapshot:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/UTLUVCAX/1912.html:text/html}
}

@article{meghdouri_analysis_2018,
	title = {Analysis of {Lightweight} {Feature} {Vectors} for {Attack} {Detection} in {Network} {Traffic}},
	volume = {8},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	abstract = {The consolidation of encryption and big data in network communications have made deep packet inspection no longer feasible in large networks. Early attack detection requires feature vectors which are easy to extract, process, and analyze, allowing their generation also from encrypted traffic. So far, experts have selected features based on their intuition, previous research, or acritically assuming standards, but there is no general agreement about the features to use for attack detection in a broad scope. We compared five lightweight feature sets that have been proposed in the scientific literature for the last few years, and evaluated them with supervised machine learning. For our experiments, we use the UNSW-NB15 dataset, recently published as a new benchmark for network security. Results showed three remarkable findings: (1) Analysis based on source behavior instead of classic flow profiles is more effective for attack detection; (2) meta-studies on past research can be used to establish satisfactory benchmarks; and (3) features based on packet length are clearly determinant for capturing malicious activity. Our research showed that vectors currently used for attack detection are oversized, their accuracy and speed can be improved, and are to be adapted for dealing with encrypted traffic.},
	language = {en},
	number = {11},
	urldate = {2019-07-30},
	journal = {Applied Sciences},
	author = {Meghdouri, Fares and Zseby, Tanja and Iglesias, Félix},
	month = nov,
	year = {2018},
	keywords = {feature selection, network attack detection, supervised learning},
	pages = {2196}
}

@inproceedings{moustafa_unsw-nb15_2015,
	title = {{UNSW}-{NB15}: a comprehensive data set for network intrusion detection systems ({UNSW}-{NB15} network data set)},
	shorttitle = {{UNSW}-{NB15}},
	abstract = {One of the major research challenges in this field is the unavailability of a comprehensive network based data set which can reflect modern network traffic scenarios, vast varieties of low footprint intrusions and depth structured information about the network traffic. Evaluating network intrusion detection systems research efforts, KDD98, KDDCUP99 and NSLKDD benchmark data sets were generated a decade ago. However, numerous current studies showed that for the current network threat environment, these data sets do not inclusively reflect network traffic and modern low footprint attacks. Countering the unavailability of network benchmark data set challenges, this paper examines a UNSW-NB15 data set creation. This data set has a hybrid of the real modern normal and the contemporary synthesized attack activities of the network traffic. Existing and novel methods are utilised to generate the features of the UNSWNB15 data set. This data set is available for research purposes and can be accessed from the link.},
	booktitle = {{MilCIS}},
	author = {Moustafa, Nour and Slay, Jill},
	month = nov,
	year = {2015},
	keywords = {telecommunication traffic, Feature extraction, computer network security, IP networks, Servers, Benchmark testing, Data models, low footprint attacks, network intrusion detection systems, network traffic, NIDS, pcap files, Telecommunication traffic, testbed, Training, UNSW-NB15 data set, UNSW-NB15 network data set},
	pages = {1--6}
}

@inproceedings{sharafaldin_toward_2018,
	address = {Funchal, Madeira, Portugal},
	title = {Toward {Generating} a {New} {Intrusion} {Detection} {Dataset} and {Intrusion} {Traffic} {Characterization}},
	shorttitle = {Toward {Generating} a {New} {Intrusion} {Detection} {Dataset} and {Intrusion} {Traffic} {Characterization}},
	abstract = {Intrusion Detection, IDS Dataset, DoS, Web Attack, Inﬁltration, Brute Force.},
	language = {en},
	urldate = {2019-09-10},
	booktitle = {{ICISSP}},
	publisher = {SCITEPRESS},
	author = {Sharafaldin, Iman and Habibi Lashkari, Arash and Ghorbani, Ali A.},
	year = {2018},
	pages = {108--116}
}

@inproceedings{bachl_walling_2019,
	address = {Orlando, FL, USA},
	title = {Walling {Up} {Backdoors} in {Intrusion} {Detection} {Systems}},
	abstract = {Interest in poisoning attacks and backdoors recently resurfaced for Deep Learning (DL) applications. Several successful defense mechanisms have been recently proposed for Convolutional Neural Networks (CNNs), for example in the context of autonomous driving. We show that visualization approaches can aid in identifying a backdoor independent of the used classifier. Surprisingly, we find that common defense mechanisms fail utterly to remove backdoors in DL for Intrusion Detection Systems (IDSs). Finally, we devise pruning-based approaches to remove backdoors for Decision Trees (DTs) and Random Forests (RFs) and demonstrate their effectiveness for two different network security datasets.},
	urldate = {2019-12-07},
	booktitle = {Big-{DAMA}},
	publisher = {ACM},
	author = {Bachl, Maximilian and Hartl, Alexander and Fabini, Joachim and Zseby, Tanja},
	year = {2019},
	keywords = {Deep Learning, Explainable AI, Network security, Poisoning attack, Pruning, Random Forests},
	pages = {8--13}
}

@inproceedings{bachl_rax_2019,
	title = {Rax: {Deep} {Reinforcement} {Learning} for {Congestion} {Control}},
	shorttitle = {Rax},
	doi = {10.1109/ICC.2019.8761187},
	abstract = {This paper proposes Reactive Adaptive eXperience based congestion control (Rax), a new method of congestion control (CC) that uses online reinforcement learning (RL) to maintain an optimum congestion window with respect to a given reward function and based on current network conditions. We use a neural network based approach that can be initialized either with random weights or with a previously trained neural network to improve stability and convergence time. As the processing of rewards in CC depends on the arrival of acknowledgements, which are delayed and received one by one, the problem is not suitable for current implementations of Deep RL. As a remedy we propose Partial Action Learning, a formulation of Deep RL that supports delayed and partial rewards. We show that our method converges to a stable, close-to-optimum solution within minutes and outperforms existing CC algorithms in typical networks. Thus, this paper demonstrates that Deep RL can be done online and can compete with classic CC schemes such as Cubic.},
	booktitle = {{ICC}},
	author = {Bachl, Maximilian and Zseby, Tanja and Fabini, Joachim},
	month = may,
	year = {2019},
	keywords = {Biological neural networks, convergence time, deep reinforcement learning, deep RL, learning (artificial intelligence), Measurement, Microsoft Windows, neural nets, neural network, online reinforcement learning, optimum congestion window, partial action learning, Rax, reactive adaptive experience based congestion control, Reinforcement learning, reward function, telecommunication computing, telecommunication congestion control, Telecommunications, TV},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/PZGRMM59/8761187.html:text/html;IEEE Xplore Full Text PDF:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/JTG9DWLB/Bachl et al. - 2019 - Rax Deep Reinforcement Learning for Congestion Co.pdf:application/pdf}
}

@article{mnih_playing_2013,
	title = {Playing {Atari} with {Deep} {Reinforcement} {Learning}},
	url = {http://arxiv.org/abs/1312.5602},
	abstract = {We present the ﬁrst deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We ﬁnd that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
	language = {en},
	urldate = {2020-01-24},
	journal = {arXiv:1312.5602 [cs]},
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	month = dec,
	year = {2013},
	note = {arXiv: 1312.5602},
	keywords = {Computer Science - Machine Learning},
	annote = {Comment: NIPS Deep Learning Workshop 2013},
	file = {Mnih et al. - 2013 - Playing Atari with Deep Reinforcement Learning.pdf:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/GMYI3I5J/Mnih et al. - 2013 - Playing Atari with Deep Reinforcement Learning.pdf:application/pdf}
}

@inproceedings{schwartz_reinforcement_1993,
	title = {A reinforcement learning method for maximizing undiscounted rewards},
	volume = {298},
	booktitle = {{ICML}},
	author = {Schwartz, Anton},
	year = {1993},
	pages = {298--305}
}

@inproceedings{mirsky_kitsune_2018,
	address = {San Diego, CA},
	title = {Kitsune: {An} {Ensemble} of {Autoencoders} for {Online} {Network} {Intrusion} {Detection}},
	isbn = {978-1-891562-49-5},
	shorttitle = {Kitsune},
	url = {https://www.ndss-symposium.org/wp-content/uploads/2018/02/ndss2018_03A-3_Mirsky_paper.pdf},
	doi = {10.14722/ndss.2018.23204},
	abstract = {Neural networks have become an increasingly popular solution for network intrusion detection systems (NIDS). Their capability of learning complex patterns and behaviors make them a suitable solution for differentiating between normal trafﬁc and network attacks. However, a drawback of neural networks is the amount of resources needed to train them. Many network gateways and routers devices, which could potentially host an NIDS, simply do not have the memory or processing power to train and sometimes even execute such models. More importantly, the existing neural network solutions are trained in a supervised manner. Meaning that an expert must label the network trafﬁc and update the model manually from time to time.},
	language = {en},
	urldate = {2020-01-24},
	booktitle = {{NDSS}},
	publisher = {Internet Society},
	author = {Mirsky, Yisroel and Doitshman, Tomer and Elovici, Yuval and Shabtai, Asaf},
	year = {2018},
	file = {Mirsky et al. - 2018 - Kitsune An Ensemble of Autoencoders for Online Ne.pdf:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/VTGHGQ3R/Mirsky et al. - 2018 - Kitsune An Ensemble of Autoencoders for Online Ne.pdf:application/pdf}
}

@inproceedings{cho_learning_2014,
	address = {Doha, Qatar},
	title = {Learning {Phrase} {Representations} using {RNN} {Encoder}–{Decoder} for {Statistical} {Machine} {Translation}},
	url = {https://www.aclweb.org/anthology/D14-1179},
	doi = {10.3115/v1/D14-1179},
	urldate = {2020-02-04},
	booktitle = {{EMNLP} 2014},
	publisher = {Association for Computational Linguistics},
	author = {Cho, Kyunghyun and van Merriënboer, Bart and Gulcehre, Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
	month = oct,
	year = {2014},
	pages = {1724--1734},
	file = {Full Text PDF:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/7CAFFWTD/Cho et al. - 2014 - Learning Phrase Representations using RNN Encoder–.pdf:application/pdf}
}

@article{hochreiter_long_1997,
	title = {Long short-term memory},
	volume = {9},
	number = {8},
	journal = {Neural computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	year = {1997},
	pages = {1735--1780}
}

@article{ha_suspicious_2016,
	title = {Suspicious traffic sampling for intrusion detection in software-defined networks},
	volume = {109},
	issn = {13891286},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1389128616301645},
	doi = {10.1016/j.comnet.2016.05.019},
	abstract = {In order to defend a cloud computing system from security attackers, an intrusion detection system (IDS) is widely used to inspect suspicious traﬃc on the network. However, the processing capacity of an IDS is much smaller than the amount of traﬃc to be inspected in a large-scaled network system. In this paper, we propose a traﬃc sampling strategy for software-deﬁned networking (SDN) that fully utilizes the inspection capability of malicious traﬃc, while maintaining the total aggregate volume of the sampled traﬃc below the inspection processing capacity of the IDS. We formulate an optimization problem to ﬁnd an appropriate sampling rate for each switch, and sample the traﬃc ﬂows in the network according to the optimal sampling rates using the SDN functionalities. The simulation and experimental results indicate that the proposed approach signiﬁcantly enhances the inspection performance of malicious traﬃc in large-sized networks.},
	language = {en},
	urldate = {2020-02-06},
	journal = {Computer Networks},
	author = {Ha, Taejin and Kim, Sunghwan and An, Namwon and Narantuya, Jargalsaikhan and Jeong, Chiwook and Kim, JongWon and Lim, Hyuk},
	month = nov,
	year = {2016},
	pages = {172--182},
	file = {Ha et al. - 2016 - Suspicious traffic sampling for intrusion detectio.pdf:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/Y5GUIJQA/Ha et al. - 2016 - Suspicious traffic sampling for intrusion detectio.pdf:application/pdf}
}

@inproceedings{murali_kodialam_detecting_2003,
	title = {Detecting network intrusions via sampling: a game theoretic approach},
	volume = {3},
	shorttitle = {Detecting network intrusions via sampling},
	doi = {10.1109/INFCOM.2003.1209210},
	abstract = {In this paper, we consider the problem of detecting an intruding packet in a communication network. Detection is accomplished by sampling a portion of the packets transiting selected network links (or router interfaces). Since sampling entails incurring network costs for real-time packet sampling and packet examination hardware, we would like to develop a network packet sampling strategy to effectively detect network intrusions while not exceeding a given total sampling budget. We consider this problem in a game theoretic framework, where the intruder picks paths (or the network ingress point if only shortest path routing is possible) to minimize chances of detection and where the network operator chooses a sampling strategy to maximize the chances of detection. We formulate the game theoretic problem, and develop sampling schemes that are optimal in this game theoretic setting.},
	booktitle = {{INFOCOM}},
	author = {Murali Kodialam and Lakshman, T.V.},
	month = mar,
	year = {2003},
	keywords = {communication network, Communication networks, Computer crime, Costs, Drugs, game theoretic problem, game theory, Game theory, Hardware, Intrusion detection, network intrusion detection, network link, packet examination hardware, packet switching, real-time packet sampling, router interfaces, Routing, sampling methods, Sampling methods, shortest path routing, telecommunication links, telecommunication network routing, telecommunication security, Telecommunication traffic},
	pages = {1880--1889 vol.3},
	file = {IEEE Xplore Abstract Record:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/Q942R9M9/1209210.html:text/html;IEEE Xplore Full Text PDF:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/7VCHCBGU/Murali Kodialam and Lakshman - 2003 - Detecting network intrusions via sampling a game .pdf:application/pdf}
}

@article{bakhoum_intrusion_2011,
	title = {Intrusion detection model based on selective packet sampling},
	volume = {2011},
	issn = {1687-417X},
	url = {https://jis-eurasipjournals.springeropen.com/articles/10.1186/1687-417X-2011-2},
	doi = {10.1186/1687-417X-2011-2},
	abstract = {Recent experimental work by Androulidakis and Papavassiliou (IET Commun 2(3):399, 2008; IEEE Netw 23(1):6, 2009) has shown that it is possible to maintain a high level of network security while selectively inspecting packets for the existence of intrusive activity, thereby resulting in a minimal amount of processing overhead. In this paper, a statistical approach for the modeling of network intrusions as Markov processes is introduced. The theoretical findings presented here confirm the earlier experimental results of Androulidakis and Papavassiliou. A common notion about network intrusion detection systems is that every packet arriving into a network must be inspected in order to prevent intrusions. This investigation, together with the earlier experimental results, disproves that notion. Additional experimental testing of a corporate local area network is reported.},
	language = {en},
	number = {1},
	urldate = {2020-02-06},
	journal = {EURASIP Journal on Information Security},
	author = {Bakhoum, Ezzat G},
	month = dec,
	year = {2011},
	pages = {2},
	file = {Bakhoum - 2011 - Intrusion detection model based on selective packe.pdf:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/8EUQES27/Bakhoum - 2011 - Intrusion detection model based on selective packe.pdf:application/pdf}
}

@article{estan_new_2003,
	title = {New directions in traffic measurement and accounting},
	volume = {21},
	language = {en},
	number = {3},
	journal = {ACM Transactions on Computer Systems},
	author = {Estan, Cristian and Varghese, George},
	year = {2003},
	pages = {44},
	file = {Estan and Varghese - New directions in traffic measurement and accounti.pdf:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/UC25Q5D3/Estan and Varghese - New directions in traffic measurement and accounti.pdf:application/pdf}
}

@inproceedings{estan_building_2004,
	address = {Portland, Oregon, USA},
	title = {Building a better {NetFlow}},
	isbn = {978-1-58113-862-7},
	url = {https://doi.org/10.1145/1015467.1015495},
	doi = {10.1145/1015467.1015495},
	abstract = {Network operators need to determine the composition of the traffic mix on links when looking for dominant applications, users, or estimating traffic matrices. Cisco's NetFlow has evolved into a solution that satisfies this need by reporting flow records that summarize a sample of the traffic traversing the link. But sampled NetFlow has shortcomings that hinder the collection and analysis of traffic data. First, during flooding attacks router memory and network bandwidth consumed by flow records can increase beyond what is available; second, selecting the right static sampling rate is difficult because no single rate gives the right tradeoff of memory use versus accuracy for all traffic mixes; third, the heuristics routers use to decide when a flow is reported are a poor match to most applications that work with time bins; finally, it is impossible to estimate without bias the number of active flows for aggregates with non-TCP traffic.In this paper we propose Adaptive NetFlow, deployable through an update to router software, which addresses many shortcomings of NetFlow by dynamically adapting the sampling rate to achieve robustness without sacrificing accuracy. To enable counting of non-TCP flows, we propose an optional Flow Counting Extension that requires augmenting existing hardware at routers. Both our proposed solutions readily provide descriptions of the traffic of progressively smaller sizes. Transmitting these at progressively higher levels of reliability allows graceful degradation of the accuracy of traffic reports in response to network congestion on the reporting path.},
	urldate = {2020-02-06},
	booktitle = {{SIGCOMM}},
	publisher = {ACM},
	author = {Estan, Cristian and Keys, Ken and Moore, David and Varghese, George},
	month = aug,
	year = {2004},
	keywords = {data summarization, network monitoring, traffic measurement},
	pages = {245--256},
	file = {Full Text PDF:/home/max/.zotero/zotero/zzt443zn.default/zotero/storage/3IVL2APH/Estan et al. - 2004 - Building a better NetFlow.pdf:application/pdf}
}

@article{zseby_sampling_2005,
	title = {Sampling and filtering techniques for {IP} packet selection},
	journal = {IETF Request for Comments RFC 5475},
	author = {Zseby, Tanja and Molina, Maurizio and Duffield, Nick and Niccolini, Saverio and Raspall, Fredric},
	year = {2009}
}